{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "import pandas as pd\n",
    "\n",
    "spark = DatabricksSession.builder.profile(\"marvelmlops\").getOrCreate()\n",
    "\n",
    "df = spark.read.table(\"samples.nyctaxi.trips\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to set up automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages.config import ProjectConfig\n",
    "import numpy as np\n",
    "from packages.paths import AllPaths\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "ALL_PATHS = AllPaths()\n",
    "\n",
    "config = ProjectConfig.from_yaml(config_path=ALL_PATHS.filename_config)\n",
    "\n",
    "df = spark.read.option(\"header\",True).csv(f'{ALL_PATHS.data_volume}/hotel_reservations.csv').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Instantiate LGBMClassifier with parameters\n",
    "model = lgb.LGBMClassifier(**config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = config.num_features\n",
    "for col in num_features:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = config.cat_features\n",
    "for cat_col in cat_features:\n",
    "    df[cat_col] = df[cat_col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df['avg_price_per_room'], bins=50)\n",
    "plt.title('Distribution of Average Price per Room')\n",
    "plt.xlabel('Average Price per Room')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude zeros from calculations\n",
    "non_zero_prices = df.loc[df['avg_price_per_room'] != 0, 'avg_price_per_room']\n",
    "\n",
    "mean_price = non_zero_prices.mean()\n",
    "median_price = non_zero_prices.median()\n",
    "\n",
    "print(f\"Mean Price: {mean_price}\")\n",
    "print(f\"Median Price: {median_price}\")\n",
    "\n",
    "for col in cat_features:\n",
    "    # Ensure the column is of type 'category'\n",
    "    if not isinstance(df[col].dtype, CategoricalDtype):\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    # Add 'Unknown' to categories if not already present\n",
    "    if 'Unknown' not in df[col].cat.categories:\n",
    "        df[col] = df[col].cat.add_categories(['Unknown'])\n",
    "    \n",
    "    # Fill NaN values with 'Unknown'\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "df[config.target] = df[config.target].map({'Not_Canceled': 0, 'Canceled': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply median imputation to null or zero values in avg_price_per_room to avoid right skewness of the data\n",
    "# check what kind of preprocessing could we perform to categorical data\n",
    "# remember to put scalling and encoding to the modelling module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['booking_status'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['booking_status'].value_counts()\n",
    "print(class_counts)\n",
    "\n",
    "class_percentages = df['booking_status'].value_counts(normalize=True) * 100\n",
    "print(class_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['booking_status_encoded'] = le.fit_transform(df['booking_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from mlflow.models import infer_signature\n",
    "from packages.config import ProjectConfig\n",
    "import json\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "ALLPATHS = AllPaths()\n",
    "\n",
    "config = ProjectConfig.from_yaml(config_path=ALLPATHS.filename_config)\n",
    "logger.info(\"Configuration loaded:\")\n",
    "print(yaml.dump(config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.set_tracking_uri(\"databricks://marvelmlops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.tracking_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = mlflow.search_runs(\n",
    "    experiment_names=[\"/Shared/cremerf-cancellation-prediction\"],\n",
    "    filter_string=\"tags.branch='week2'\",\n",
    ").run_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['booking_status_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_target = df['booking_status_encoded'].isnull().sum()\n",
    "print(f\"Missing values in target variable: {missing_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "\n",
    "# Count zeros in numeric columns\n",
    "zero_counts = (df[numeric_cols] == 0).sum()\n",
    "\n",
    "# Count NaN/null values in numeric columns\n",
    "nan_counts = df[numeric_cols].isna().sum()\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Zero Count': zero_counts,\n",
    "    'NaN/Null Count': nan_counts\n",
    "})\n",
    "\n",
    "# Display the summary\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical features\n",
    "numeric_features = [\n",
    "    'no_of_adults', 'no_of_children', 'no_of_weekend_nights', 'no_of_week_nights',\n",
    "    'lead_time', 'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
    "    'avg_price_per_room', 'no_of_special_requests'\n",
    "]\n",
    "categorical_features = [\n",
    "    'type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved', \n",
    "    'arrival_year', 'arrival_month', 'arrival_date', 'market_segment_type', \n",
    "    'repeated_guest'\n",
    "]\n",
    "\n",
    "# Preprocessing for numeric data: convert data types and scale\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())  # Scale data\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data: fill missing values and apply one-hot encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # Convert categorical data\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # This will drop other columns not listed explicitly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and target\n",
    "X = df.drop('booking_status', axis=1)\n",
    "y = df['booking_status']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True).csv('/Volumes/mlops_students/cremerfederico29/data/hotel_reservations.csv').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
